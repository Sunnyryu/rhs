## R

#### R Study

```R
# mpg 데이터 셋을 대상으로 7:3 비율로 학습데이터와 검정데이터로 각각 샘플링한 후
각 단계별로 분류분석을 수행하시오.
조건) 변수모델링 : x변수(displ + cyl + year), y변수(cty)

#단계1 : 학습데이터와 검정 데이터 생성
idx <- sample(1: nrow(mpg), nrow(mpg) * 0.7)
train <- mpg[idx, ] # 학습데이터
dim(train)
test <- mpg[-idx, ] # 검정데이터
dim(test)

#단계2 : formula 생성
# 도시 주행마일수 <- 실린더, 엔진크기, 제조년도
formula <- cty ~ displ + cyl + year

#단계3 : 학습데이터에 분류모델 적용
mpg_train <- ctree(formula, data=train)

#단계4 : 검정데이터에 분류모델 적용
mpg_test <- ctree(formula, data=test)

#단계5 : 분류분석 결과 시각화
plot(mpg_test)

#단계6 : 분류분석 결과 해설
실린더가 5이하이면 엔진크기에 의해서 23개가 분류되고, 실린더가 5이상이고,
6이하이면 27개가 분류되고, 6을 초과한 경우 21개가 분류된다.

library(rpart)
weather = read.csv("./data/weather.csv", header=TRUE)

#단계2 : 데이터 샘플링
weather.df <- weather[, c(-1,-14)]
nrow(weather.df)
idx <- sample(1:nrow(weather.df), nrow(weather.df)*0.7)
weather_train <- weather.df[idx, ]
weather_test <- weather.df[-idx, ]

#단계3 : 분류모델 생성
weather_model <- rpart(RainTomorrow ~ ., data = weather.df)
weather_model # Humidity 중요변수

#단계4 : 예측치 생성 : 검정데이터 이용
weater_pred <- predict(weather_model, weather_test)
weater_pred

#단계5 : 예측 확률 범주화('Yes Rain', 'No Rain')
weater_class <- ifelse(weater_pred[,1] >=0.5, 'No Rain', ' Yes Rain')

#단계6 : 혼돈 행렬(confusion matrix) 생성 및 분류정확도 구하기
table(weater_class, weather_test$RainTomorrow)
# weater_class No Yes
# No Rain 83 6
# Yes Rain 2 19
# (83 + 19) / nrow(weather_test)
# [1] 0.9272727
```

```
비지도학습(unSupervised Learning)
  데이터에 의한 학습을 통해 최적의 판단이나 예측을 가능하게 해주는 기계학습 방법의 하나로 어떤 입력에 대해서 어떤 결과가 출력되는지 사전지식이 없는 상태에서 컴퓨터 스스로 공통점과 차이점 등의 패턴을 찾아서 규칙(rule)을 생성하고, 분석 결과를 도출해내는 방식
  Y변수(정답)가 없기 때문에 검정 데이터를 이용하여 모델을 평가할 수 없음


군집분석(Cluster Analysis)
  데이터 간의 유사도를 정의하고 그 유사도에 가까운 것부터 순서대로 합쳐 가는 방법으로 그룹(군집)을 형성한 후 각 그룹의 성격을 파악하거나 그룹 간의 비교분석을 통해서 데이터 전체의 구조에 대한 이해를 돕고자 하는 탐색적 분석 방법
  유사도 거리(distance)를 이용 – 유클리디안(Euclidean) 거리도 측정한 거리정보를 이용해서 분석 대상을 몇 개의 집단으로 분류
  군집분석에 의해서 그룹화된 군집은 변수의 특성이 그룹 내적으로는 동일하고, 외적으로는 이질적인 특성을 가짐
  용도 – 고객의 충성도에 따라서 몇 개의 그룹으로 분류하고, 그룹별로 맞춤형 마케팅 및 프로모션 전략을 수립하는데 활용

  군집분석(Cluster Analysis) 목적
  데이터 셋 전체를 대상으로 서로 유사한 개체 들을 몇 개의 군집으로 세분화하여 대상 집단을 정확하게 이해하고, 효율적으로 활용하기 위함

군집분석(Cluster Analysis) 중요사항
  군집화를 위해서 거리 측정에 사용되는 변인은 비율척도나 등간척도이어야 하며, 인구 통계적 변인, 구매패턴 변인, 생활 패턴 변인 등이 이용
  군집분석에 사용되는 입력 자료는 변수의 측정단위와 관계없이 그 차이에 따라 일정하게 거리를 측정하기 때문에 변수를 표준화하여 사용하는 것이 필요
  군집화 방법에 따라 계층적 군집분석과 비계층적 군집분석으로 분류

  군집분석(Cluster Analysis)에 이용되는 변인
  인구 통계적 변인 : 거주지, 성별, 나이, 교육수준, 직업, 소득수준 등
  구매패턴 변인 : 구매상품, 1회 평균 거래액, 구매횟수, 구매주기 등
  생활패턴 변인 : 생활습관, 가치관, 성격, 취미 등

군집분석(Cluster Analysis) 특징
  전체적인 데이터 구조를 파악하는데 이용된다.
  관측대상 간 유사성을 기초로 비슷한 것끼리 그룹화(Clustering)
  유사성은 유클리디안 거리를 이용한다
  분석결과에 대한 가설 검정이 없다
  반응변수(y 변수)가 존재하지 않는 데이터마이닝 기법이다.
  규칙(Rule)을 기반으로 계층적인 트리 구조를 생성한다.
  활용분야는 구매패턴에 따른 고객분류, 충성도에 따른 고객분류 등

군집분석(Cluster Analysis) 절차
  단계 1] 분석 대상의 데이터에서 군집분석에 사용할 변수 추출
  단계 2] 계층적 군집분석을 이용한 대략적인 군집의 수 결정
  단계 3] 계층적 군집분석에 대한 타당성 검증(ANOVA 분석)
  단계 4] 비계층적 군집분석을 이용한 군집분류
  단계 5] 분류된 군집의 특성 파악 및 업무 적용

  유클리디안 거리(Euclidean distance)
  두 점 사이의 거리를 계산하는 방법
  관측대상 p와 q의 대응하는 변량 값의 차가 작으면, 두 관측대상은 유사하다고 정의하는 식
  유클리디안 거리 계산식은 관측대상 p와 q의 대응하는 변량 값의 차의 제곱의 합에 제곱근을 적용한 결과

  matrix 객체를 대상으로 dist() 함수를 이용하여 유클리디안 거리를 생성함

  matrix 객체의 값이 서로 가까울수록 유클리디안 거리값이 작은 값으로 나타나고, 거리가 멀수록 큰 값으로 나타남

```


```R
#유클리디안 거리 계산
x <- matrix(1:9, nrow=3, by=T)
x
dist<-dist(x, method="euclidean")
dist

#1과 2, 2와 3은  유클리디안 거리 1과 3보다는 가깝고
s<- sum((x[1,] - x[2,])^2)  #1행과 2행의 변량의 차의 제곱의 합
sqrt(s)  

s<- sum((x[1,] - x[3,])^2)  #1행과 3행의 변량의 차의 제곱의 합
sqrt(s)

```

```
계층적 군집분석(Hierarchical Clustering) 절차
    개별대상 간의 거리에 의하여 가장 가까운 대상부터 결합하여 나무 모양의 계층구조를 상향식(Bottom-up)으로 만들어가면서 군집을 형성하는 방법
    계층적 군집 분석은 군집이 형성되는 과정을 파악할 수 있다는 장점과 자료의 크기가 큰 경우 분석이 어렵다는 단점!
    군집화된 결과를 plot() 함수를 이용하여 시각화하면 덴드로그램(Dendrogram)에 의해서 클러스터 형태로 시각화해줌!
    덴드로그램에서 Height는 해당 군집에 대한 유클리디안 거리를 의미!
    계층적 군집분석결과에서 분석자가 원하는 군집수 만큼 인위적으로 군집을 만들 수 있음 (stats::cutree(계층적 군집분석결과, k=군집수))
군집 대상 간의 거리를 산정하는 기준에 따라 계층적 군집 분석 분류
    단일결합기준(최소거리 이용)
    완전결합기준(최대거리 이용)
    평균결합기준(평균거리 이용)
    중심결합 기준(중심 값의 거리 이용)
    ward(유클리디안 제곱거리)

비계층적 군집분석(Cluster Analysis)
    군집의 수가 정해진 상태에서 군집의 중심에서 가장 가까운 개체를 하나씩 포함해 나가는 방법
    군집수를 미리 알고 있는 경우 군집 대상의 분포에 따라 군집의 초기값을 설정해 주면, 초기값에 가장 가까운 거리에 있는 대상을 하나씩 더해 가는 방식으로 군집화를 수행
    계층적 군집분석을 통해 대략적인 군집의 수를 파악하고 이를 초기 군집 수로 설정하여 비계층적 군집분석을 수행하는 것이 효과적
    K-means clustering  (stats::kmeans())

  비계층적 군집분석(Cluster Analysis)  장점
    대량의 자료를 빠르고 쉽게 분류할 수 있음

  비계층적 군집분석(Cluster Analysis) 단점
    군집의 수를 미리 알고 있어야함
```

```R
# 유클리디안 거리 계산 계층적 군집 분석
x <- matrix(1:9, nrow=3, by=T)
x
dist<-dist(x, method="euclidean")
dist

#유클리드 거리 matrix를 이용한 군집화
hc <- hclust(dist) #클러스터링 적용

plot(hc)
```
![Deepin스크린샷_select-area_20190923172558](https://i.imgur.com/c1p9QHQ.png)

```R
#유클리디안 거리 계산 계층적 군집 분석 2
interview <- read.csv("./data/interview.csv", header=TRUE, fileEncoding = "CP949")
names(interview)
head(interview)

#유클리디안 거리 계산
interview_df <- interview[c(2:7)]
idist <- dist(interview_df)
head(idist)

hc <- hclust(idist)
plot(hc, hang=-1)  #hang=-1 은 덴드로그램에서 음수값을 제거
rect.hclust(hc, k=3, border="red")

#유사한 데이터끼리 그룹화한 결과, 3개 그룹 (8,10,7,12,15), (2,1,4,6,13), (3,5,9,11,14)

#군집별 특성을 보기위해서 군집별 subset 생성
g1 <- subset(interview, no==108|no==110|no==107|no==112|no==115)
g2 <- subset(interview, no==102|no==101|no==104|no==106|no==113)
g3 <- subset(interview, no==103|no==105|no==109|no==111|no==114)

summary(g1)  #종합점수 평균:71.6, 인성평균 :9.4 , 자격증 없음
summary(g2)  #종합점수 평균:75.6, 인성평균 :14.8 , 자격증 있음
summary(g3)  #종합점수 평균:62.8, 인성평균 :11 , 자격증 있음, 없음
```
![Deepin스크린샷_select-area_20190923173229](https://i.imgur.com/xTSoLrq.png)
![Deepin스크린샷_select-area_20190923173516](https://i.imgur.com/0Njs3su.png)
