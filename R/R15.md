## R

#### R Study

```
요인 분석  
    변수들의 상관성을 바탕으로 변수를 정제하여 상관관계 분석이나 회귀분석에 설명변수(독립변수)로 사용
    상관 분석  
    요인분석 과정에서 변수들이 상관관계를 분석하여 변수 간의 관련성을 분석하는데 이용
회귀 분석  
    인과관계를 분석하는데 중요한 자료를 제공

요인 분석 (Factor Analysis) 목적
    자료의 요약 : 변인을 몇 개의 공통된 변인으로 묶음
    변인 구조 파악 : 변인들의 상호관계 파악(독립성등)
    불필요한 변인 제거 : 중요도가 떨어진 변수 제거
    측정 도구 타당성 검증 : 변인들이 동일한 요인으로 묶이는지 확인  
요인 분석에 대한 활용 방안
    측정 도구가 정확히 측정했는지를 알아보기 위해서 측정 변수들이 동일한 요인으로 묶이는지를 검정한다(타당성 검정)
    변수들의 상관관계가 높은 것끼리 묶어서 변수를 정제 (변수 축소)
    변수의 중요도를 나타내는 요인적재량이 0.4 미만이면 설명력이 부족한 요인으로 판단하여 제거 (변수 제거)
    요인분석에서 얻어지는 결과를 이용하여 상관분석이나 회귀분석의 설명변수로 활용

공통요인으로 변수 정제
    특정 항목으로 묶여 지는데 사용되는 요인수 결정은 주성분 분석방법과 상관계수 행렬을 이용한 초기 고유값을 이용
    단계1] 주성분 분석 - 변동량(분산)에 영향을 주는 주요 성분을 분석하는 방법으로 요인분석에서 사용될 요인의 개수를 결정하는데 주로 이용
    단계2] 고유값으로 요인수 분석 – 고유값이란 어떤 행렬로부터 유도되는 실수값을 의미함, 일반적으로 변화량의 (총분산)을 기준으로 요인수를 결정하는데 이용
    상관계수 행렬을 대상으로 초기 고유값 요인수 분석
    eigen()은 상관계수 행렬을 대상으로 초기 고유값과 고유벡터를 계산하는 함수
```


```R
# 공통 요인으로 변수를 정제하는 요인분석
# 6개 과목 (s1~s6)
# 점수벡터 (5점 만점, 척도:5)
s1 <- c(1, 2, 1, 2, 3, 4, 2, 3, 4, 5)  #자연과학
s2 <- c(1, 3, 1, 2, 3, 4, 2, 4, 3, 4)  # 물리화학
s3 <- c(2, 3, 2, 3, 2, 3, 5, 3, 4, 2)  #인문사회
s4 <- c(2, 4, 2, 3, 2, 3, 5, 3, 4, 1)  # 신문방송
s5 <- c(4, 5, 4, 5, 2, 1, 5, 2, 4, 3)  #응용수학
s6 <- c(4, 3, 4, 4, 2, 1, 5, 2, 4, 2)  # 추론통계
name <-1:10  #각 과목의 문제 이름


#데이터 프레임 생성
subject <- data.frame(s1, s2, s3, s4, s5, s6)
subject

#주성분 분석으로 요인수 구하기
help(prcomp)  #주성분 분석 수행 함수
pc <- prcomp(subject) # scale = TRUE
summary(pc)  # 변동량으로 볼때 주성분 요인수는 2개로 가정할 수 있음
plot(pc)
```
![Deepin스크린샷_select-area_20190919172734](https://i.imgur.com/x4MgyVL.png)
```R
# 고유값으로 요인 수 분석
en <- eigen(cor(subject)) # $values : 고유값, $vectors : 고유벡터  
names(en) # "values"  "vectors"
en$values
en$vectors
en$values # $values : 고유값(스칼라) 보기
plot(en$values, type="o") # 고유값을 이용한 시각화
```
![Deepin스크린샷_select-area_20190919172900](https://i.imgur.com/I2S3lZX.png)

```R
#베리 맥스 요인 회전법
result <- factanal(subject, factors=2, rotation="varimax")
result
#p-value는 0.0232로 유의수준 0.05보다 적어서 요인수가 부족하다는 의미!

result <- factanal(subject, factors=3, rotation="varimax", scores="regression")
result

plot(result$scores[, c(1:2)], main="Factor1과 Factor2의 요인점수 행렬")
text(result$scores[, 1], result$scores[, 2], labels=name, cex=0.7, pos=3, col="red")
points(result$loadings[, c(1:2)], pch=19, col="blue")
text(result$loadings[, 1], result$loadings[, 2], labels=rownames(result$loadings), cex=0.8, pos=3, col="blue")
```
![Deepin스크린샷_select-area_20190920093439](https://i.imgur.com/jazkyyP.png)


```R
library(scatterplot3d)
#요인 점수별 분류
Factor1 <- result$scores[, 1]
Factor2 <- result$scores[, 2]
Factor3 <- result$scores[, 3]

#scatterplot3d(밑변, 오른쪽 변, 왼쪽변, type)
scatterplot3d(Factor1 , Factor2, Factor3 , type='p')
d3 <- scatterplot3d(Factor1 , Factor2, Factor3 , type='p')
#요인적재량 표시
loadings1 <- result$loadings[, 1]
loadings2 <- result$loadings[, 2]
loadings3 <- result$loadings[, 3]
d3$points3d(loadings1, loadings2, loadings3, bg="red", pch=21, cex=2, type="h")
```
![Deepin스크린샷_select-area_20190920093858](https://i.imgur.com/5WN5xHU.png)
![Deepin스크린샷_select-area_20190920094210](https://i.imgur.com/8Z13lWf.png)


```R
# 요인 분석 결과를 이용하여  변수 묶기->  상관분석이나 회귀분석에서 독립변수로 사용할 수 있는 파생변수 생성
#Factor1은 응용과학
#Factor2은 응용수학
#Factor3은 자연과학

app <- data.frame(subject$s5, subject$s6)
soc <- data.frame(subject$s3, subject$s4)
net <- data.frame(subject$s1, subject$s2)

#산술평균을 계산하여 요인별 파생변수 생성
app_science <- round((app$subject.s5 + app$subject.s6)/ncol(app), 2)
soc_science <- round((soc$subject.s3 + soc$subject.s4)/ncol(soc), 2)
net_science <- round((net$subject.s1 + net$subject.s2)/ncol(net), 2)

#상관관계 분석
subject_factor_df <- data.frame(app_science, soc_science, net_science)
cor(subject_factor_df)

> cor(subject_factor_df)
            app_science soc_science net_science
app_science   1.0000000  0.43572654 -0.68903024
soc_science   0.4357265  1.00000000 -0.02570212
net_science  -0.6890302 -0.02570212  1.00000000
#해석 > '응용과학' 기분으로 '사회과학'은 양의 상관성을 나타내고, '자연과학'은 음의 상관성

```

```R
#잘못 분류된 요인 제거로 변수 정제
#음료수 제품의 11개의 변수 (친밀도, 적절성, 만족도 3가지 영역)
# 특정 변수가 묶일 것으로 예상되는 요인이 묶이지 않는 경우, 해당 변수를 제거하는 정제 작업이 필요함
install.packages("memisc")
library(memisc)
data.spss <- as.data.set(spss.system.file("./data/drinking_water.sav"))
data.spss
# 제품 친밀도 (q1 : 브랜드, q2:친근감, q3:익숙함, q4:편안함)
# 제품 적절성 (q5 : 가격적절성, q6:당도적절성, q7:성분적절성)
# 제품 만족도 (q8 : 음료의 목넘김, q9:맛, q10:향 ,q11:가격)

drinking_water <- data.spss[1:11]  
drinking_water_df <- as.data.frame(data.spss[1:11])
str(drinking_water_df)

#요인 분석
result <- factanal(drinking_water_df, factors=3, rotation="varimax")

#Uniqueness는 11개변수가 0.5 이하의 값이면 모두 유효하다고 볼 수 있음
#Loadings : Factor1 (q8~q11), Factor2(q1~q3), Factor3(q4~q7)
#p-value는 0.0255로 유의수준 0.05보다 작기 때문에 요인수 선택에 문제가 있다고 볼 수 있음
#(p-value는  chi_square 검정의 결과로서 기대치와 관찰치에 차이가 있음을 알려주는 확률값)

dw_df <-drinking_water_df[-4]
str(dw_df)

s <- data.frame(dw_df$q8, dw_df$q9, dw_df$q10, dw_df$q11)  #만족도
c <- data.frame(dw_df$q1, dw_df$q2, dw_df$q3)  #친밀도
p <- data.frame(dw_df$q5, dw_df$q6, dw_df$q7)  #적절성

satisfaction <-round( (dw_df$q8+dw_df$q9+dw_df$q10+dw_df$q11)/ncol(s), 2)
closeness <-round( (dw_df$q1+dw_df$q2+dw_df$q3)/ncol(c), 2)
pertinence <-round( (dw_df$q5+dw_df$q6+dw_df$q7)/ncol(p), 2)

#상관관계 분석
dwf_df <- data.frame(satisfaction, closeness, pertinence)
colnames(dwf_df) <-c("제품 만족도", "제품 친밀도", "제품 적절성")
cor(dwf_df)
# 해석> 제품 친밀도와 제품 적절성이 상관관계가 높은 변수들임
```

```
상관분석(correlation Analysis)
    데이터 내의 두 변수간의 관계를 알아보기 위한 분석 방법
    상관계수(Correlation coefficient)를 이용
    상관분석은 연속형, 순서형 자료를 대상으로 하고, 범주형은 불가능함
    두 변수 간의 연관된 정도만 제시하고 있으며 회귀분석을 통해 두 변수 간 원인과 결과의 인과관계의 방향, 정도, 모형 적합을 통한 함수관계를 검토할 수 있음
    두 변수의 상관성에 대한 예측이므로, 가설과 검증을 통해 통계적 유의성을 판단
    등간성이나 비율성이 존재하지 않음
    결정계수(R square)는 상관계수를 제공하여 나오는 값으로, 회귀분석에서 설명력을 의미
상관분석 절차
    변수들 간의 산점도 그리기
    산점도를 통해 직선관계를 파악
    상관계수 계산
    상관계수로 자료 해석
    상관관계의 유무, 정도에 따라 회귀분석 실시
```
![Deepin스크린샷_select-area_20190920104820](https://i.imgur.com/VlMPH2p.png)

```R
#상관 관계 분석
result <- read.csv("./data/product.csv", header=TRUE)
head(result)
str(result)
sd(result$제품_친밀도); sd(result$제품_적절성); sd(result$제품_만족도)
[1] 0.9703446
[1] 0.8596574
[1] 0.8287436
cor(result$제품_친밀도, result$제품_적절성)
[1] 0.4992086

cor(result$제품_적절성, result$제품_만족도)
#0.7668527

cor(result$제품_친밀도+result$제품_적절성, result$제품_만족도)
[1] 0.7017394

#상관계수에 따라 색의 농도로 시각화
library(corrgram)
corrgram(result)

corrgram(result, upper.panel=panel.conf) #위쪽에 상관계수 추가
corrgram(result, lower.panel=panel.conf) #아래쪽에 상관계수 추가
```
![Deepin스크린샷_select-area_20190920111320](https://i.imgur.com/CYyGoEu.png)
```
기본 result
```
![Deepin스크린샷_select-area_20190920111554](https://i.imgur.com/rnYISf0.png)

```
위쪽 상관계수 추가
```
![Deepin스크린샷_select-area_20190920111617](https://i.imgur.com/GNTEcQN.png)
```
아래쪽 상관계수 추가
```


```R
# 상관성, 밀도곡선, 유의확률 시각화
install.packages("PerformanceAnalytics")
library(PerformanceAnalytics)
상관성, p값(*), 정규분포 시각화
chart.Correlation(result, histogram=, pch="+")
```
![Deepin스크린샷_select-area_20190920111843](https://i.imgur.com/pnmcNCS.png)

```R
#회귀 변수
product <- read.csv("./data/product.csv", header=TRUE, fileEncoding = "CP949")
head(product)
str(product)

y<-product$제품_만족도  #종속변수
x<-product$제품_적절성  #독립변수
df <- data.frame(x, y)

# 단순 선형회귀 모델 생성 lm(y~x, data)
library(stats)
result.lm <- lm(formula=y~x, data=df)
result.lm
# Y=0.7789 +0.7393*X

# 생성된 선형회귀 모델의 적합값과 잔차 계산
names(result.lm)    #모델 관련 정보 확인
fitted.values(result.lm)[1:2]   #모델의 적합값 확인 3.735963, 2.996687
head(df, 1)   #관측값  x=4, y=3

Y=0.7789 +0.7393*4
Y     #3.7361

#오차는 관측값-적합값
3 - 3.735963     #-0.735963

residuals(result.lm)[1:2]  #-0.7359630, -0.9966869

#관측값은 잔차+ 적합값
-0.7359630 + 3.735963    #3

#선형회귀분석 모델 시각화
plot(formula=y~x, data=result)
abline(result.lm, col="red")   #회귀선

#선형회귀분석 결과
summary(result.lm)

# Multiple R-squared:  0.5881 는 독립변수에 의해서 종속변수가 얼마만큼 설명되었는가 (회귀모델의 설명력)
# Multiple R-squared 값은 독립변수와 종속변수 간의 상관관계를 나타내는 결정계수
# 설명력이 1에 가까울수록 설명변수(독립변수)가 설명을 잘한다고 판단할 수 있음 => 변수의 모델링이 잘 되었다는 의미

#Adjusted R-squared:  0.5865은 오차를 감안하여 조정된 R 값으로 (실제 분석은 이 값을 적용)

#F-statistic:   374 회귀모델의 적합성을 나타내며    
#p-value: < 2.2e-16
#F-statistic와 p-value를 이용하여 회귀모델 자체를 신뢰할 수 있는지 판단
#p-value가 0.05보다 매우 작기 때문에 회귀선이 모델에 적합하다고 볼 수 있음

#x            0.73928    0.03823  19.340  < 2e-16 ***
x변수의 t=19.340 , p-value는 < 2e-16 이므로  p-value가 0.05보다 매우 작기 때문에 "제품의 가격과 품질을 결정하는 제품 적절성은 제품 만족도에 양의 영향을 미침" 연구가설 채택


```
![Deepin스크린샷_select-area_20190920134203](https://i.imgur.com/dJyT6JT.png)
```R
product <- read.csv("./data/product.csv", header=TRUE, fileEncoding = "CP949")
head(product)
str(product)

y<-product$제품_만족도       #종속변수
x1<-product$제품_적절성     #독립변수1
x2<-product$제품_친밀성   #독립변수2
df <- data.frame(x1, x2, y)


#다중 회귀 분석
result.lm <- lm(formula=y~x1+x2, data=df)
result.lm

#다중 공선성문제 확인
# 지금 사용하는 r에서 car 패키지가 안되서 터미널에서 apt-get install r-cran-car로 설치하였음
library(car)
vif(result.lm)     #분산팽창요인(VIF) - 결과값이 10 이상인 경우에는 다중 공선성문제를 의심해 볼수 있습니다.


#다중 회귀 분석 결과 보기
summary(result.lm)

#Multiple R-squared:  0.5975,    Adjusted R-squared:  0.5945
#F-statistic: 193.8 on 2 and 261 DF,  p-value: < 2.2e-16
#x1           0.68522    0.04369  15.684  < 2e-16 ***
#x2           0.09593    0.03871   2.478   0.0138 *  

#x1는 제품의 적절성이 제품 만족도에 미치는 영향 t검정통계량 15.684,
#x2는 제품의 친밀도가 제품 만족도에 미치는 영향 t검정통계량 2.478
x1, x2의 유의 확률은 0.05보다 작기 때문에 제품 만족도에 양의 영향을 끼침(연구 가설 채택)

#상관계수(결정계수) 0.5975 다소 높은 상관관계를 나타냄, 설명력은 59.45%
#회귀모델의 적합성 f검정통계량 193.8, p-value < 2.2e-16이므로 0.05 보다 매우 낮으므로 회귀모델은 적합하다고 볼 수 있음


################다중 공선성 문제 해결과 모델 평가 ##############
#iris의 Sepal.Length(꽃받침 길이)를 종속변수로 지정하고 Sepal.Width, Petal.Length, Petal.Width을 독립변수로 ...

fit <- lm(formula= Sepal.Length ~ Sepal.Width+Petal.Length+Petal.Width, data=iris)
fit

#다중공선성 문제 확인
vif(fit)
Sepal.Width Petal.Length  Petal.Width
   1.270815    15.097572    14.234335

#다중공선성 문제가 의심되는 변수의 상관계수 확인
cor(iris[, -5])
Sepal.Length Sepal.Width Petal.Length Petal.Width
Sepal.Length    1.0000000  -0.1175698    0.8717538   0.8179411
Sepal.Width    -0.1175698   1.0000000   -0.4284401  -0.3661259
Petal.Length    0.8717538  -0.4284401    1.0000000   0.9628654
Petal.Width     0.8179411  -0.3661259    0.9628654   1.0000000


#학습데이터와 검정 데이터를 7:3으로 표본 추출
x <- sample(1:nrow(iris), 0.7*nrow(iris))  #70% 표본 추출, 행번호 추출
train <- iris[x, ] #학습데이터
test <- iris[-x, ] #검정데이터

#Petal.Width 변수를 제거한 후 학습데이터로부터 회귀모델 생성
model <- lm(formula= Sepal.Length ~ Sepal.Width+Petal.Length, data=iris)
model
summary(model)
Call:
lm(formula = Sepal.Length ~ Sepal.Width + Petal.Length, data = iris)

Residuals:
     Min       1Q   Median       3Q      Max
-0.96159 -0.23489  0.00077  0.21453  0.78557

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept)   2.24914    0.24797    9.07 7.04e-16 ***
Sepal.Width   0.59552    0.06933    8.59 1.16e-14 ***
Petal.Length  0.47192    0.01712   27.57  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.3333 on 147 degrees of freedom
Multiple R-squared:  0.8402,	Adjusted R-squared:  0.838
F-statistic: 386.4 on 2 and 147 DF,  p-value: < 2.2e-16

#꽃받침의 너비가 꽃받침의 길이에 영향을 미침
#꽃잎의 길이가 꽃받침의 길이에 영향을 줌!
```

```R
#검정데이터에 회귀모델 적용 예측값 생성 후 모델 평가
#회귀방정식
Y = 2.2491 + 0.5955 + 0.4719
head(train, 1)
(관측치 5)
Y = 2.2491 + 0.5955*3.3 + 0.4719*1.4
Y => 에측치 4.8749
# 오차는 5 - 4.8749 => 0.1251임

#stats::predict(model, data)
pred <- predict(model, test)
pred

# 모델 평가는 상관계수를 이용
cor(pred, test$Sepal.Length)
#  0.929988
# 예측치와 실제 관측치는 상관계수가 0.929988이므로 1에 가까우므로 매우 높은 상관관계를 가짐
# 모델의 정확도가 아주 높다고 볼 수 있음

# 로지스틱 회귀분석
weather <- read.csv("./data/weather.csv",  header=T, stringsAsFactors = F)
dim(weather)  # 관측치: 366 변수: 15
str(weather)

weather_df <- weather[, c(-1, -6, -8, -14)]

#y변수(RainTomorrow)의 로짓변환 : (0, 1)로 생성
weather_df$RainTomorrow[weather_df$RainTomorrow=='Yes']<-1
weather_df$RainTomorrow[weather_df$RainTomorrow=='No']<-0
weather_df$RainTomorrow <- as.numeric(weather_df$RainTomorrow)
head(weather_df)

#학습 데이터와 검정데이터 생성(7:3)
idx <- sample(1:nrow(weather_df), nrow(weather_df)*0.7)
train <- weather_df[idx,]
test <- weather_df[-idx,]


#학습 데이터로부터 로지스틱 회귀모델 생성
weather_model <- glm(RainTomorrow ~ ., data=train, family='binomial')
weather_model
summary(weather_model)

# 로지스틱 회귀모델 예측치 생성
pred <- predict(weather_model, newdata=test, type="response") #response는 예측결과를 0~1사이의 확률값으로 예측치를 반환
pred    # 예측치가 1에 가까울수록 비율 확률이 높다고 할 수 있다
#예측치를 이항형으로 변환 : 0.5이상이면 1, 0.5미만이면 0
result_pred <- ifelse(pred >=0.5, 1, 0)
result_pred


table(result_pred)   
table(result_pred, test$RainTomorrow)
#result_pred  0  1
#          0 90 10
#          1  2  8
# 분류 정확도는(90+8) / (90+10+2+8) = 0.8909091
```

```R
#ROC Curve 를 이용한 모델 평가
install.packages("ROCR")
library(ROCR)
pr <- prediction(pred, test$RainTomorrow)
prf <- performance(pr, measure="tpr", x.measure="fpr")
plot(prf)
#왼쪽 상단의 계단모양의 빈 공백만큼이 분류 정확도에서 오분류(missing)를 나타낸다.
```
![Deepin스크린샷_select-area_20190920170111](https://i.imgur.com/Bp08pvA.png)
