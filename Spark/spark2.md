## Hello Spark 2

#### 스파크

```
sparkSQL

JSON형식 파일 / Parquet(파케) 형식 파일 / ORC 형식 파일 / JDBC를 지원하는 DB / 하이브 호환 테이블 / 스파크 SQL 전용 테이블 등의 데이터 셋을 지원함

데이터셋으로부터 조건에 맞는 데이터 추출 / JSON의 키와 테이블의 컬럼 등, 특정한 이름으로 데이터 추출, 복수의 데이터셋 결합, 그룹 단위로 집약, 다른 형식의 구조화된 데이터셋으로 변환 가능
```

```
스파크 SQL은 DataFrame과 테이블 형식의 데이터, Data Sources API를 통해 데이터셋을 처리하는 통일된 방법을 이용자들에게 제공
어휘분석, 구문분석, 의미분석, 최적화를 통해 RDD처리로 변환하고 클러스터상에서 분산처리를 실행하는 기능 제공
```

```
spark SQL의 개념

코드는 적게 작성 / 데이터는 적게 읽음 / 어려운 일은 옵티마이저에게 맡김

```

```
스파크 SQL을 이용한 데이터처리 기술방법

DataFrame으로 데이터처리 기술

  간결하고 가독성 높은 코드로 데이터처리 기술 / 옵티마이저에 의한 최적화

  스파크 SQL은 구조화되지 않은 데이터셋을 직접 다루지 못함. (ex : binary data)
  RDD의 변환 이용 -> 데이터셋을 변형 -> 변형된 데이터셋을 나타내는 RDD를 DataFrame에 변환하는 방식으로 변환처리나 spark sql 조합 !

테이블 형식의 데이터셋 이용

  스파크SQL CLI
    명령줄 도구 / HiveQL을 이용하여 테이블 작성 / 테이블에 데이터를 로드, 테이블에 대화식으로 쿼리 발행함으로써 분산처리 가능

  Thrift JDBC/ODBC server
    JDBC/ODBC를 경유해 스파크 SQL에 의한 데이터처리가능하게 해줌 (HiveServer2) 기반으로 만들어짐 / 쿼리의 병렬 실행이나 이용자 인증을 고려해 만들어짐

  
