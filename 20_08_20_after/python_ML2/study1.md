m## study

```
머신러닝~~ 

지도학습 / 비지도학습 / 강화학습!

지도학습(레이블된 데이터 , 직접 피드백, 출력 및 미래 예측!)

비지도 학습 (레이블 및 타깃 없음 , 피드백 없음, 데이터에서 숨겨진 구조 찾기)

강화학습 (결정 과정, 보상 시스템, 연속된 행동에서 학습)
```

```

지도학습의 목적은 레이블(머신러닝에서 특정 샘플에 할당된 클래스)된 훈련 데이터에서 모델을 학습하여 본 적 없는 미래 데이터에 대해 예측을 만드는 것! 
(지도란 희망하는 출력 신호(레이블)가 없는 일련의 샘플..)
-> 스팸메일처럼 .. 스팸인지 스팸이 아닌지가 구별이 되어 있는 데이터로 모델을 학습하여 새로운 이메일이 왔을 때.. 스팸인지 아닌지 확인 시켜줌!

(스팸 필터처럼 개별 클래스 레이블이 있는 지도학습을 분류(클래시피케이션) , 연속적인 값을 출력하는 회귀(리그레이션이 있음) )

레이블,훈련데이터 -> ML 알고리즘 -> 예측모델(새로운 데이터가 들어간)-> 예측
```

```
분류 - 클래스 레이블 예측 (클래시피케이션) / 과거의 관측을기반으로 새로운 샘플의 범주형 클래스 레이블을 예측하는 것이 목적 
(클래스 레이블은 인산적이고 순서가 없어 샘플이 속한 그룹으로 이해할 수 있음)

스팸 이메일 감지는 전형적인 이진 분류 (두개의 클래스 사이를 구분하려고 머신 런이 알고리즘이 일련의 규칙을 학습)

지도학습 알고리즘으로 학습한 예측 모델은 훈련 데이터셋에 있는 모든 클래스 레이블을 새로운 샘플에 할당할 수 있음 (다중분류 -> 글자인식..)
(알파벳 각 글자를 손으로 쓴 이미지 샘플을 모아서 훈련 데이터셋을 구성 / 새로운 글자를 입력으로 제공하면 예측 모델이 일정한 정확도로 알파벳 글자를 예측할 것! / 0~9까지 숫자가 훈련 데이터셋에 없다면 머신러닝 시스템은 숫자를 인식하지 못할 것임!)

분류에서는 음성클래스와 양성클래스가 있다고 생각하고 구분할 수 있는 규칙을 결정 경계라고 하며, x1,x2값이 주어지면 두가지 범주중에 하나로 분류!

회귀(연속적인 출력 값 예측 / 예측변수(설명변수, 입력)와 연속적인 반응 변수(출력,타깃)가 주어졌을 때 출력 값을 예측하는 두 변수 사이의 관계를 찾음!)

시험 정적을 예측한다고 하면 시험 공부에 투자한 시간과 최종 점수 사이의 관계가 있다면 두 값으로 훈련 데이터를 만들고 모델을 학습할 수 있음! 

선형 회귀 (입력x와 타깃 y가 주어지면 샘플과 직선 사이 거리가 최소가 되는 직선을 그을 수 있음, 일반적으로 평균 제곱 거리를 사용! /학습한 직선의 기울기와 절편을 사용하여 새로운 데이터의 출력값을 예측!)
```

```
강화학습은 머신러닝의 또다른 종류 / 환경과 상호작용하여 시스템(에이전트) 성능을 향상시키는 것! (환경의 현재 상태정보는 보상 신호를 포함하기에 지도학습과 관련된 거로 생각할 수 있음 ) - 피드백은 정답 레이블이나 값이 아니라 보상 함수로 얼마나 행동이 좋은 지를 측정한 값 / 시스템은 환경과 상호작용하여 보상이 최대화되는 일련의 행동을 강화 학습으로 학습 (탐험적인 시행착오방식이나 신중하게 세운 계획을 사용)

(환경 (보상 상태)-> 에이전트 -> (행동) -> 환경)
예를 들어 체스게임이라고 하면 체스판의 상태(환경)따라 기물의 이동을 결정(시스템[에이전트]) , 보상은 게임을 종료했을 떄 승리하거나 패배하는 것으로 정의 가능!
```

```
강화학습의 일반적인 구조는 강화학습 에이전트가 환경과 상호작용하여 보상을 최대화하는 것임! (양의 보상과 음의 보상과 연관)

보상은 체스 게임의 승리나 패배처럼 전체 목표를 달성하는 것으로 정의 가능! ( 체스에서 기물의 이동으로 나타난 결과는 각기 다른 환경 상태로 생각할 수 있음!)

체스판의 특정 위치에 도달하는 것이 긍정적인 이벤트와 연관 가능! (좋은 기물을 잡거나 게임을 끝낼 찬스 마련 ) / 부정적인 이벤트도 연고나 가능 (기물을 잃게 되거나 게임이 끝날 기물이 위협받음 ) / 강화학습은 즉시 또는 지연된 피드백을 기초로 하여 보상을 최대화하는 일련의 단계를 학습 

(분류, 회귀, 군집)
```

```

비지도 학습 (레이블되지 않거나 구조를 알 수 없는 데이터를 다룸 / 기법사용 시 알려진 출력 값이나 보상 함수의 도움을 받지 않고 의미 있는 정보를 추출하기 위해 데이터 구조를 탐색할 수 있음!)

군집(서브그룹 찾기) - 사전 정보 없이 쌓여 있는 그룹 정보를 의미 있는 서브 그룹 또는 클러스터로 조직하는 탐색적 데이터 분석 기법입니다. (분석 과정에서 만든 각 클러스터는 어느정도 유사성을 공유하고 다른 클러스터와는 비슷하지 않은 샘플 그룹을 형성!) / 군집을 비지도 분류라고 하는 이유가 있음 , 클러스터링은 정보를 조직화하고 데이터에서 의미 있는 관계를 유도하는 훌륭한 도구! 

예를 들어 마케터가 관심사를 기반으로 고객을 그룹으로 나누어 각가에 맞는 마케팅 프로그램을 개발할 수 있음! / 군집이 어떻게 레이블되지 않은 유사도를 기반으로 세 개의 개별적인 그룹으로 조직화하는지 보여줌!
```

```

차원축소(데이터 압축) / 비지도 학습의 또 다른 하위 분야는 차원축소 (고차원의 데이터를 다루어야할 때 사용!) / 하나의 관측 샘플에 많은 측정 지표가 있음, 이로 인해 머신 러닝 알고리즘의 계산 성능과 저장 공간의 한계에 맞딱뜨릴 수 있음 

비지도 차원 축소는 잡음 데이터를 제거하기 위해 특성 전처리 단계에서 종종 적용하는 방법 / 잡음 데이터는 특정 알고리즘의 예측 성능을 감소시킬 수 있음 / 관련정보를 대부분 유지, 더 작은 차원의 부분 공간으로 데이터 압축 

(전처리 단계에서 데이터 압축에도 유용하게 사용! - 비지도 학습)
```

```
샘플은 데이터셋에서 하나의 행으로 표현 / 센터미터 단위의 측정 값은 열에 저장되어 있으며 데이터셋의 특성이라고 함!

지도학습과 비지도 학습이 섞여있는 준지도 학습도 있음! 
```

```
전처리 -> 학습 -> 평가 -> 예측
전처리(레이블,원본데이터 -> 훈련, 테스트 세트) - 특성 추출 및 스케일 조정 , 특성 선택, 차원 축소 , 샘플링 
학습(학습알고리즘) - 모델 선택, 교차 검증 , 성능 지표, 하이퍼파라미터 최적화
평가(최종모델 -> 레이블 ) (최종모델 -> 새로운 데이터)
예측(새로운 데이터 -> 레이블)

전처리 (데이터 형태 갖추기) : ex) 나무가 있다고 하면 유용한 특성은 나무의 색, 높이, 길이와 너비 등이 되겟담. (순수 나무가 아닌 특성들을 이용)

훈련 데이터넷에서 잘 작동하고 새로운 데이터에서도 잘 일반화되는지 확인하려면 데이터셋을 랜덤하게 훈련 세트와 테스트 세트로 나누어야함! / 훈련 세트에서 머신 러닝 모델을 훈련하고 최적화함! / 테스트 세트는 별도로 보관하고 최종모델을 평가하는 맨 마지막에 사용!

예측모델 훈련과 선택 : 여러모델을 비교하기 전에 먼저 성능을 측정할 지표를 결정해야함! 분류에서 널리 사용되는 지표는 정확도 (정확히 분류된 샘플 비율이라고 생각하자!)

다양한 교차방법을 사용(훈련세트와 검증세트로 훈련데이터를 나눔!)

하이퍼 파라미터 (데이터에서 학습하는 파라미터가 아니라 모델 성능을 향상하기 위해 사용하는 다이얼로 생각할 수 있음 ) - 모델 성능을 상세하게 조정하기 위해 하이퍼파라미터 최적화를 사용!

모델을 평가하고 본 적 없는 샘플로 예측- 최적의 모델을 선택한 후에는 테스트 세트를 사용하여 이전에 본 적이 없는 데이터에서 얼마나 성능을 내는지 예측하여 일반화 오차를 예상 / 모델을 사용하여 미래의 새로운 데이터를 예측할 수 있음(성능을 만족한다면!) / 특성 스케일조정과 차원 축소 같은 단계에서 사용한 파라미터는 훈련 세트만 사용하여 얻은 것임을 주목해야함! 나중에 동일한 파라미터를 테스트 세트는 물론 새로운 모든 샘플을 변환하는 데 사용! 그렇지 않으면 테스트 세트에서 측정한 성능은 과도하게 낙관적인 결과가 되옵니다!
```
