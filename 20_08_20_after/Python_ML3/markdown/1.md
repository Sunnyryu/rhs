## Scikit-learn

```
classfication / regression / clustering / semi-supervised learning / feature selection / feature extraction / manifold learning .... 등 있음

supervised machine learing (지도학습..)

trainin data / training labels -> model 
test data -> pediction <- model 
test labels -> evaluation <- prediction 

clf = RandomForestClassifier()
clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)
clf.score(X_test, y_test)

unsupervised machine learing 

training data -> model 
test data -> new view / Transformation <- Model

pca = PCA()
pca.fit(X_train)

X_new = pca.transform(X_test) 차원축소등

estimator(모델을 지정..)

predict / transform 
Classficaiton , regression , clustering  / preprocessing , dimensionality reduction , feature selection, feature extraction

데이터 검증

훈련 데이터 / 테스트 데이터
fit을 잘했는지... => 데이터를 여러개로 나눠서 테스트와 트레이닝을 해서 좋은 점수를 내서 잘 한 거를 선택..

clf = SVC()
clf.fit(X_train, Y_train)

파라미터를 변경하면서 제일 좋은 값을 찾음!

문장을 토큰화해서 단어로 벡터화시키는 것도!

파라미터가 좋은지 찾음
그리드 vs 랜덤

supervised learning (정답이 있는 ... / 데이터를 가지고 구매할 지 안 할 지를 예측하는 등의...)

classfication / regression 등..

tree.DecisionTreeClassifier() => 디시전 트리 분류자 생성..
(DecisionTreeClassifier 모델을 선언한 후에 fit 함수를 사용하면 학습이 진행)
flt 메소드는 입력데이터를 모델에 전달하여 학습시키는 함수 명령
predict 함수는 정답을 [0, 1] 중 하나로만 나타냄
predicg_proba 함수를 사용하면 값이 비율로 출력

Decision tree 알고리즘은 숫자만 이해할 수 있기 때문에 0, 1, 2로 카테고리가 구분
plot_tree는 디시전 트리를 만들어줌 tree.plot_tree(clf.fit(X,y), filled=True) => clf.fit(X,y)는 디시전 트리에 보내려는 데이터 / filled 조건을 해주면 색으로 구분이 가능함!
plt.figure(figsize=(20,10))을 이용하면 그래프를 크게 볼 수 있음

당뇨병 데이터

outcome을 구해야하는데 supervised machine learing이므로 정답이 있는 데이터로 실습




 
```