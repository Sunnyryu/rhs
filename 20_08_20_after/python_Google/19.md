# 머신러닝(추천시스템2)

```
심층 신경망 모델 

측면 피쳐(즉, 그 밖의 모든 피쳐)를 사용하는 어려움 쿼리 ID/항목 ID). 그 결과, 모델은 다음 항목에서만 쿼리할 수 있음 (훈련 세트에 존재하는 사용자 또는 품목)

인기있는 아이템들은 특히 유사성 측정으로 도트 제품을 사용할 때 모두에게 추천되는 경향이 있음 
(특정 사용자의 이익을 포착하는 것이 좋음)

심층신경망(DNN) 모델은 이러한 매트릭스 인자화의 한계를 다룰 수 있음
DNN은 (네트워크의 입력 계층의 유연성 때문에) 질의 기능과 항목 특징을 쉽게 통합할 수 있으며, 이는 사용자의 특정 관심사를 포착하고 권고사항의 관련성을 개선하는 데 도움이 될 수 있음.

소프트맥스 DNN 권장사항
입력은 사용자 쿼리 / 출력은 크기가 다음 숫자와 같은 확률 벡터 ( 상관 관계를 나타내는 말뭉치의 항목 (유트브 영상을 클릭하거나 볼 수 있는 확률))

입력 
(조밀한특징 - 마지막 시계 이후 시간과 시간 / 드문드문한 특징 (역사 및 국가보기)

매트릭스 인자화 접근 방식과 달리 다음과 같은 사이드 피쳐를 추가할 수 있음
(연령 또는 국가 입력벡터를 X로 나타냄)

모델 아키텍처
모델 아키텍처는 모델의 복잡성과 표현성을 결정합니다. 숨겨진 도면층 및 비선형 활성화 기능(예: ReLU)을 추가함으로써 모형이 데이터의 더 복잡한 관계를 캡처할 수 있음

매개변수의 수를 증가시키면 일반적으로 모델은 훈련하기가 더 어려워지고 서비스 비용이 더 많이 듬(마지막 숨겨진 층의 생산량을 함수에 의해 나타낼 것!)

소프트맥스 출력: 예측 확률 분포
최대치는 확률 1 / 모든 항목에 0이 아닌 확률을 할당하여 점수가 높은 항목에 더 높은 항목을 부여함!)

DNN 및 매트릭스 인자화
소프트맥스 모델과 매트릭스 인자화 모델에서, 시스템은 항목당 하나의 내장 벡터를 학습함
```

```
소프트맥스 훈련

훈련 데이터

소프트맥스 훈련 데이터는 사용자가 상호작용한 항목의 벡터(확률 분포로 표현됨)와 쿼리 특징으로 구성
모형의 변수는 다른 층의 가중치

네거티브 샘플링

손실함수는 두개의 확률 벡터를 비교하기 때문에.. 말 뭉치 크기가 너무 크면 손실 경사도를 개선하기 위해 힘들 수 있음

포지티브 항목(그라운드 진리 벡터에서 활성화된 항목)에서만 그라데이션 계산 시스템을 설정할 수 있음
(단, 시스템이 양성 쌍으로만 훈련하는 경우, 모델은 아래와 같이 폴딩으로 인해 어려움을 겪을 수 있음)

그라데이션 값을 위한 항목

모든 양수 항목(대상 레이블에 표시되는 항목)
음수 항목의 샘플( 참조)
부정적인 샘플링을 위한 다른 전략이 있음
```

```
매트릭스 인자화 VS 소프트 맥스

DNN 모델은 Matrix Factorization의 많은 한계를 해결하지만 일반적으로 훈련과 질의에 더 많은 비용이 듬
```
|   | 매트릭스 인자화| 소프트맥스  |
|---|---|---|
| 쿼리 피쳐  | 포함하기 어려움  | 포함가능  |
|  콜드 스타트 | 어휘가 부족한 쿼리/아이템 쉽게 처리 못함 (일부 휴리스틱스를 사용가능- 새로운 쿼리의 경우 유사한 쿼리의 평균 임베딩)  | 새 쿼리를 쉽게 처리  |
|  폴딩 |  WALS에서 관측되지 않은 무게 조정 쉽게 줄이기 가능 | 접기 쉽다, 마이너스 표본 추출이나 중력 등의 기법을 사용할 필요가 있음  |
| 훈련 규모  |  매우 큰 규모 쉽게 확장 가능 / 입력 매트릭스가 희박한 경우에만 가능 | 매우 큰 규모로 확장이 어려움, 해싱,마이너스 샘플링 등 일부 기법 사용 가능  |
| 서빙 규모   |  임베딩 U,V는 정적이며, 후보들을 미리 계산하여 저장 가능, 아이템 임베딩 V는 정직이므로 저장 가능 |  쿼리 임베등인 일반적으로 쿼리 시간에 계산되어야 하므로 모델을 서비스 하는 데 더 많은 비용이 듬!  |

```
매트릭스 인자화는 보통 큰회사에 더 나은 선택!(확장하기 쉽고, 쿼리 비용이 저렴하며 접기 쉬움)
DNN 모델은 개인화된 선호도를 더 잘 포착할 수 있지만, 훈련하기가 더 어렵고 질의 비용이 더 많이 듬. 
DNN 모델은 더 많은 기능을 사용하여 캡처 관련성을 높일 수 있기 때문에 점수를 매트릭스 인자화보다 DNN 모델이 더 바람직함. 
DNN 모델은 대개 접히는 것이 허용
```

```
검색

매트릭스 인자화 모델의 경우, 쿼리(또는 사용자) 임베딩이 정적으로 알려져 있으며, 시스템은 사용자 임베딩 매트릭스에서 간단히 조회할 수 있음.

DNN 모델의 경우, 시스템은 형상 벡터에서 네트워크를 실행하여 서비스 시간에 쿼리를 내장하는 것을 계산함.

내장 후 내장 공간에 가까운 항목을 검색할 수 있음!
관련 항목 권장사항에서 유사한 접근법을 사용할 수 있음.

대규모 검색

임베딩 공간에서 가장 가까운 이웃을 계산하기 위해 시스템은 모든 잠재적 후보자에게 점수를 매길 수 있음 

쿼리 임베딩이 정적인 경우 (시스템은 오프라인에서 철저한 채점을 수행하고 쿼리의 상위 후보 목록을 사전 계산 및 저장할 수 있음)
```

```
점수

후보생성이 끝나면 다른 모델이 생성된 후보를 점수 매기고 순위를 매겨 디스플레이 할 아이템 세트를 선택

추천 시스템은 서로 다른 소스를 사용하는 예를 가질 수 있음

행렬 요인화 모델의 관련 항목.
개인 설정을 설명하는 사용자 기능.
"로컬" 대 "불편한" 항목, 즉 지리적 정보를 고려하는 것.
인기 품목 또는 트렌드 품목.
소셜 그래프, 즉 친구들이 좋아하거나 추천하는 항목.

시스템은 이러한 서로 다른 출처를 공통의 후보 풀로 결합하여 단일 모델에 의해 점수가 매겨지고 그 점수에 따라 순위가 매겨짐.

쿼리 피쳐(예: 사용자 감시 기록, 언어, 국가, 시간)
비디오 피쳐(예: 제목, 태그, 비디오 포함)
시스템은 모델 예측에 따라 후보 풀의 비디오 순위를 매길 수 있음.

후보 생성기 점수를 매기지 않는 이유
후보 생성기는 점수를 계산하기 때문에(내장 공간의 유사성 측정과 같은) 순위 지정에도 사용할 수 있음. 그렇지만 일부 시스템은 여러 개의 후보 발전기의 의존하며, 다른 것과 점수가 비교가 안될 수 있기에.. 
더 적은 예로 시스템은 더 많은 기능과 더 복잡한 모델을 사용하여 컨텍스트를 더 잘 포착할 수 있음.

채점을 위한 목표 함수 선택 
채점 기능의 선택은 항목의 순위, 궁극적으로는 권고사항의 품질에 큰 영향을 미칠 수 있음.

클릭률 최대화
채점 기능이 클릭에 최적화되면 시스템은 클릭 베이트 비디오를 권장할 수 있음(좋은 사용자 환경은 만들지 못함)

시계 비율 최대화 
점수 매기기 기능이 시청 시간에 최적화되면 시스템이 매우 긴 비디오를 추천할 수 있으며 이는 사용자 경험 저하를 초래할 수 있음 

다양성 증대 및 세션 감시 시각 극대화
짧은 비디오를 추천하되, 사용자가 계속 작업할 가능성이 높은 비디오를 추천
```

```
재순위
추천제도의 마지막 단계에서, 시스템은 추가적인 기준이나 제약조건을 고려하도록 후보자들의 순위를 재지정할 수 있음. 
한 가지 다시 순위를 매기는 방식은 일부 후보를 제거하는 필터를 사용하는 것

신선도, 다양성, 공정성에 대해 간략히 논함!

신선도
대부분의 권고 시스템은 현재 사용자 기록과 최신 항목과 같은 최신 사용 정보를 통합하는 것을 목표
(웜 스타트(warm-start)는 훈련 시간을 현저히 줄일 수 있음 - 매트릭스 인자화에서 모델의 이전 인스턴스에 존재했던 항목에 대한 임베딩을 웜 스타트)

다양성
시스템이 항상 쿼리 임베딩에 '가장 근접한' 항목을 추천한다면, 후보자들은 서로 매우 유사한 경향이 있음 
(장르나 기타 메타데이터를 기준으로 항목의 순위를 다시 매겨 다양성 보장 / 다른 목표 함수 사용 / 다른 소스 사용하여 훈련 )

공정성
당신의 모델은 모든 사용자를 공정하게 대해야 함.(모델이 무의식적인 편견을 학습하고 있지 않은지 확인)

(디자인과 개발에 다양한 관점을 포함, 종합적인 데이터 세트에 대한 ML 모델 훈련 데이터가 부족시 보조데이터 추가)



```