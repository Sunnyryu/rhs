# 머신러닝

```
TensorFlow

TensorFlow Estimators <- 높은 수준의 개체 지향 API
tf.layers, tf.losses, tf.metrics <- 일반 모델 구성요소용 재사용 가능 라이브러리
TensorFlow Python <- C ++ 커널을 래핑하는 오퍼레이션 제공
TensorFlow C++
CPU GPU TPU <- 커널은 하나 이상의 플랫폼에서 작동!

에스티메이터(tf.estimator)	높은 수준의 OOP API
tf.layers/tf.losses/tf.metrics	일반 모델 구성요소용 라이브러리
텐서플로우	낮은 수준의 API
```

```
텐서플로
텐서는 다차원 배열입니다. 넘파이(NumPy) ndarray 객체와 비슷하며, tf.Tensor 객체는 데이터 타입과 크기를 가지고 있습니다. 또한 tf.Tensor는 GPU 같은 가속기 메모리에 상주할 수 있습니다. 텐서플로는 텐서를 생성하고 이용하는 풍부한 연산 라이브러리(tf.add, tf.matmul, tf.linalg.inv 등.)를 제공합니다. 이러한 연산은 자동으로 텐서를 파이썬 네이티브(native) 타입으로 변환합니다.

넘파이 배열과 tf.Tensor의 가장 확연한 차이는 다음과 같습니다:

텐서는 가속기 메모리(GPU, TPU와 같은)에서 사용할 수 있습니다.
텐서는 불변성(immutable)을 가집니다.


텐서와 넘파이는 자동으로 변환이 가능하지만 호스트 메모리로 복사가 필요함!
텐서플로에서 "배치(replacement)"는 개별 연산을 실행하기 위해 장치에 할당(배치)하는 것입니다
명시적 지침이 없을 경우 텐서플로는 연산을 실행하기 위한 장치를 자동으로 결정하고, 필요시 텐서를 장치에 복사


텐서플로는 다음을 이루어짐 
그래프 프로토콜 버퍼
분산된 그래프를 실행하는 런타임

이 두 구성요소는 자바 컴파일러 및 JVM과 유사합니다. JVM이 여러 하드웨어 플랫폼에서 구현되는 것과 마찬가지로 텐서플로우도 여러 CPU와 GPU에서 구현됩니다.

에스티메이터(Estimator)
tf.Estimator 클래스의 인스턴스로서, 텐서플로우 그래프를 작성하고 텐서플로우 세션(session)을 실행하는 로직을 캡슐화합니다. 
여기에서 설명한 것과 같이 나만의 맞춤 에스티메이터를 만들거나 다른 사용자가 작성한 사전 제작된 에스티메이터를 인스턴스화할 수 있습니다.
```

```
pandas
Pandas는 열 중심 데이터 분석 API입니다. 입력 데이터를 처리하고 분석하는 데 효과적인 도구이며, 여러 ML 프레임워크에서도 Pandas 데이터 구조를 입력으로 지원

pandas의 기본 데이터 구조는 두 가지 클래스로 구현됩니다.

DataFrame은 행 및 이름 지정된 열이 포함된 관계형 데이터 테이블이라고 생각할 수 있습니다.
Series는 하나의 열입니다. DataFrame에는 하나 이상의 Series와 각 Series의 이름이 포함됩니다.

DataFrame 객체는 string 열 이름과 매핑되는 'dict'를 각각의 Series에 전달하여 만들 수 있습니다. Series의 길이가 일치하지 않는 경우, 누락된 값은 특수 NA/NaN 값으로 채워집니다. 예를 들면 다음과 같습니다.

하지만 대부분의 경우 전체 파일을 DataFrame으로 로드

위의 예에서는 DataFrame.describe를 사용하여 DataFrame에 관한 흥미로운 통계를 보여줍니다. 또 다른 유용한 함수는 DataFrame.head로, DataFrame 레코드 중 처음 몇 개만 표시

Pandas의 또 다른 강력한 기능은 그래핑입니다. 예를 들어 DataFrame.hist를 사용하면 한 열에서 값의 분포를 빠르게 검토

더 복잡한 단일 열 변환에는 Series.apply를 사용가능 Python map 함수처럼, Series.apply는 인수로 lambda 함수를 허용하며, 이는 각 값에 적용

색인
Series와 DataFrame 객체 모두 식별자 값을 각 Series 항목이나 DataFrame 행에 할당하는 index 속성을 정의합니다.

기본적으로 생성 시 Pandas는 소스 데이터의 순서를 나타내는 색인 값을 할당합니다. 생성된 이후 색인 값은 고정됩니다. 즉, 데이터의 순서가 재정렬될 때 변하지 않습니다.

DataFrame.reindex를 호출하여 수동으로 행의 순서를 재정렬합니다. 예를 들어 다음은 도시 이름을 기준으로 분류하는 것과 효과가 같습니다.

색인 재생성은 DataFrame을 섞기(임의 설정하기) 위한 좋은 방법입니다. 아래의 예에서는 배열처럼 된 색인을 NumPy의 random.permutation 함수에 전달하여 값을 섞습니다. 이렇게 섞인 배열로 reindex를 호출하면 DataFrame 행도 같은 방식으로 섞입니다.

DataFrame.reindex를 호출하여 수동으로 행의 순서를 재정렬합니다. 예를 들어 다음은 도시 이름을 기준으로 분류하는 것과 효과가 같습니다.

색인 재생성은 DataFrame을 섞기(임의 설정하기) 위한 좋은 방법입니다. 아래의 예에서는 배열처럼 된 색인을 NumPy의 random.permutation 함수에 전달하여 값을 섞습니다. 이렇게 섞인 배열로 reindex를 호출하면 DataFrame 행도 같은 방식으로 섞입니다.
```

```
텐서플로우의 기초 개념을 학습
텐서플로우의 LinearRegressor 클래스를 사용하여 입력 특성 하나를 기반으로 지역별 주택 가격 중앙값을 예측
평균 제곱근 오차(RMSE)를 사용하여 모델 예측의 정확성을 평가
초매개변수를 조정하여 모델의 정확성을 개선

확률적 경사하강법의 성능에 악영향을 줄 수 있는 의도치 않은 정렬 효과를 방지하고자 데이터를 무작위로 추출 

모델을 학습시키려면 텐서플로우 Estimator API가 제공하는 LinearRegressor 인터페이스를 사용
(특성정의 및 특성 열 구성 -> 타겟 정의 -> linear regressor 구성 -> 입력 함수 정의 -> 모델 학습 -> 모델 평가)
학습 데이터를 텐서플로우로 가져오려면 각 특성에 들어있는 데이터 유형을 지정

범주형 데이터: 텍스트로 이루어진 데이터입니다. 이 실습의 주택 데이터 세트는 범주형 데이터를 포함하지 않지만 주택 양식, 부동산 광고 문구 등의 예를 보게 될 수도 있음

수치 데이터: 정수 또는 부동 소수점 숫자이며 숫자로 취급하려는 데이터입니다. 이후에도 설명하겠지만, 우편번호 등의 수치 데이터는 범주형으로 취급하는 경우도 있음

텐서플로우에서 특성의 데이터 유형을 지정하려면 특성 열이라는 구조체를 사용
특성 열은 특성 데이터에 대한 설명만 저장하며 특성 데이터 자체는 포함하지 않음

LinearRegressor를 사용하여 선형 회귀 모델을 구성, 미니 배치 확률적 경사하강법(SGD)을 구현하는 GradientDescentOptimizer를 사용하여 이 모델을 학습

(경사 제한은 경사가 너무 커져서 경사하강법이 실패할 경우를 대비해 너무 크게 바꾸면 안되여!)

텐서플로우에 데이터 전처리 방법 및 모델 학습 중의 일괄 처리, 셔플, 반복 방법을 알려주는 입력 함수를 정의 (linearRegressor를 가져오려면 (데이터를))

pandas 특성 데이터를 NumPy 배열의 dict로 변환 -> 텐서플로의 Dataset API사용 -> 데이터 세트 개체 생성 -> 배치 사이즈 크기의 배치로 나누어 에포치만큼 반복

입력 함수에서 데이터 세트에 대한 반복자를 만들고 다음 데이터 배치를 LinearRegressor에 반환

linear_regressor로부터 train()을 호출하여 모델을 학습가능! / 
my_feature 및 target을 인수로 전달할 수 있도록 my_input_fn을 lambda에 래핑

모델이 학습 중에 학습 데이터에 얼마나 맞춰졌는지 확인하기 위해 학습 데이터로 예측을 실행(학습 오차는 모델이 학습 데이터에 얼마나 맞춰졌는지를 나타내는 척도이지만 모델이 새 데이터로 일반화되는 정도를 측정하지는 않음)

평균 제곱 오차(MSE)는 해석하기가 어려울 수 있으므로 평균 제곱근 오차(RMSE)를 대신 참고하는 경우가 많습니다. RMSE의 장점은 원래 타겟과 동일한 척도로 해석할 수 있다는 것

오차를 줄이기 위해 전반적 요약 통계를 참조하여 예측과 타겟의 일치율을 조사할 수 있음

모델 초매개변수 조정

학습 오차는 점차 감소합니다. 처음에는 급격히 감소하다가 학습이 수렴됨에 따라 결국 한계에 다다릅니다.
학습이 수렴되지 않았다면 더 오래 실행해 보세요.
학습 오차가 너무 천천히 감소하는 경우 학습률을 높이면 더 빨리 감소할 수 있습니다.
학습률이 너무 높다면 정반대 현상이 나타나기도 합니다.
학습 오차가 크게 요동한다면 학습률을 낮춰보세요.
학습률을 낮추면서 단계 수 또는 배치 크기를 늘리면 좋은 결과가 나타나는 경우가 많습니다.
배치 크기가 너무 작아도 불안정성이 나타날 수 있습니다. 처음에는 100, 1000 등의 큰 값을 사용한 후 성능이 악화되지 않는 선까지 낮추세요.
효과는 데이터에 따라 달라지므로 이러한 경험칙을 무조건적으로 따라서는 안 됩니다. 실험과 검증을 항상 반복하세요.
```

```
다른 두 특성의 비율로 합성 특성을 만든다
새 특성을 선형 회귀 모델의 입력으로 사용한다
입력 데이터에서 이상점을 식별 및 삭제하여 모델의 효율성을 개선함

입력 함수를 설정하고 모델 학습용 함수를 정의

작업 1: 합성 특성 사용해 보기

성능이 높다는 것은 회귀선이 데이터에 잘 부합하고 최종 RMSE가 낮다는 의미

이상점 식별 (보정 데이터를 보면 대부분의 산포점이 직선을 이룹니다. 이 선은 수직에 가까운데, 여기에 대해서는 나중에 설명합니다. 지금은 선에서 벗어난 점에 대해 집중할 때입니다. 이러한 점은 비교적 적은 편입니다.

rooms_per_person의 히스토그램을 그려보면 입력 데이터에서 몇 개의 이상점을 발견할 수 있습니다.)
```

```
steps: 총 학습 반복 횟수입니다. 한 단계에서 한 배치의 손실을 계산한 후, 이 값을 사용하여 모델의 가중치를 한 번 수정합니다.
batch size: 하나의 단계와 관련된 예시의 수(임의로 선택됨)입니다. 예를 들어 SGD의 batch size는 1입니다.

periods: 보고의 세부사항을 제어합니다. 예를 들어 periods가 7로 설정되고 steps가 70으로 설정되면 실습에서 10단계마다(또는 7번) 손실 값을 출력합니다. 초매개변수와 달리 periods의 값을 수정하지 않아도 됩니다. periods를 수정해도 모델이 학습하는 내용은 변경되지 않습니다.
```

