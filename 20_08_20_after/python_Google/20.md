# 머신러닝(테스팅 / 디버깅)

```
데이터를 변형 후 모델 훈련 / 모델을 사용하여 예측을 하는 단계

ML 모델을 디버그하여 모델이 작동하도록 하는 경우. 모델이 작동하면 모델의 품질을 프로덕션 읽기용으로 최적화

모델에서 저조한 성능을 디버깅하기 위해 기존 프로그래밍에서보다 더 광범위한 원인에 대해 조사

모델 성능이 저하되는 몇 가지 원인

예측력 부족 / 하이퍼 파라미터 최적값이 아닌 값으로 설정 / 데이터에는 오류와 이상 징후가 포함
피쳐 엔지니어링 코드에는 버그 포함 / 머신러닝 모델을 디버깅하는 것은 실험을 실행하는 데 걸리는 시간만큼 복잡 / 반복 주기가 더 길고 오류 공간이 더 넓다는 점을 감안할 때 독특하고 어려운것

하나 또는 두개의 피쳐를 사용하는 간단한 모델부터 만들고 디버깅을 해봄

다양한 피쳐와 하이퍼 파라미터 값을 사용해 모델을 작동 (모델을 최대한 단순화하여 디버깅 간소화) 

피쳐추가, 튜닝 하이퍼 파라미터, 모델 용량증가, 모델이 변경될 대마다 매트릭스를 다시 수행하여 모델 품질이 향상되는 지 확인 -> 이와 같은 게 잘 안되면 모델을 디버깅함!
```

```
데이터 및 기능 디버깅 

낮은 품질의 데이터는 당신의 모델 성능에 상당한 영향을 미칠 것
나쁘게 예측한 후에 그것의 존재를 추측하는 대신 입력에서 저품질 데이터를 탐지하는 것이 훨씬 더 쉬움!

데이터 스키마를 사용하여 입력데이터 확인 
데이터를 모니터링하려면 데이터가 충족해야 하는 규칙을 작성하여 예상 통계 값과 데이터를 지속적으로 확인 (이러한 데이터 규칙집합을 데이터 스키마라고 함!)

형상 데이터의 경우 범위 및 분포를 이해 / 범주형 형상의 경우 가능한 값 집합을 이해

스키마에 정의된 규칙으로 인코딩! 

ex)
사용자가 제출한 등급이 항상 1에서 5 사이인지 확인하십시오.
영어 텍스트 기능의 경우 "the"가 가장 자주 발생하는지 확인하십시오
```

```
이상 징후
범주형 변수의 예기치 않은 값
예상치 못한 데이터 분포
분할이 양호한 품질인지 확인

테스트 및 훈련 분할은 입력 데이터를 동등하게 대표해야함
테스트와 훈련 분할이 통계적으로 다르면 훈련 데이터는 시험 데이터를 예측하는 데 도움이 안됨!

분할의 통계 속성을 모니터링/ 속성이 분산되면 플레그가 올림 / 각 분할에서 예저 비율이 일정하게 유지되는 지 테스트함! (데이터가 8:2라면 계속 8:2로 유지되어야함)

테스트 엔지니어링된 데이터

Raw data(로우 데이터)는 유효할 수 있지만, 모델은 공학적 피쳐 데이터만 볼 수 있음.
공학적 데이터는 원시 입력 데이터와 매우 다르게 보이기 때문에 공학적 데이터를 별도로 확인해야함.
엔지니어링된 데이터에 대한 이해도를 바탕으로 단위 테스트를 작성
ex)
모든 숫자 형상은 0과 1 사이에서 스케일링
단일 열 인코딩 벡터에는 단일 1 및 N-1 0만 들어 있음
결측 데이터는 평균 또는 기본값으로 대체
변환 후 데이터 배포는 기대에 부합(z-점수를 사용하여 정규화한 경우 z-점수의 평균은 0)
특이치는 스케일링 또는 클리핑으로 처리
```

```
모델 디버깅

모델 디버깅에 첫번째는 데이터 디버깅 

데이터가 라벨을 예측할 수 있는 지 확인 
(기준선 설정 / 쓰기 및 테스트 실행 / 하이퍼 파라미터 값 조정)

모형이 레이블을 예측할 수 있는지 확인

기준선 설정
모델을 기준선과 비교하는 것은 모델의 품질을 빠르게 테스트하는 것

새 모델을 개발할 때는 단순 휴리스틱을 사용하여 레이블을 예측하여 기준선을 정의
훈련된 모델이 기준값보다 더 나쁜 성능을 보이면 모델을 개선

ex)
가장 예측 가능한 기능에만 대해 훈련된 선형 모델 사용.
분류에서는 항상 가장 일반적인 레이블을 예측하십시오.
회귀 분석에서는 항상 평균 값을 예측하십시오.

하이퍼 파라미터 값 조정

학습 비율 : 전형적으로, ML 라이브러리는 자동으로 학습 속도를 설정 (문제가 어려울수록 손실이 감소하기 전에 모델을 더 많이 훈련시켜야 한다는 점을 기억)

정규화
교육 데이터에 대한 정규화 없이 모델을 예측할 수 있는지 확인
그런 다음 모형이 교육 데이터에 지나치게 적합한 경우에만 정규화를 추가

선형 모델의 경우 모형의 크기를 줄여야 한다면 L1 정규화 / 모델의 안정성을 높이려면 L2 정규화 선택 / 모델의 안정성을 높이면 모델 훈련을 보다 재현할 수 있음! 

심층 신경 네트워크 모델을 정규화하려면 드롭아웃 정규화를 사용하기.
중퇴는 단일 그라데이션 단계를 위해 네트워크 계층에서 고정된 비율의 뉴런을 무작위로 선택하는 것을 제거

트레이닝 에폭시
하나의 시대를 위해 훈련해야 하며, 지나치게 과하게 맞지 않는 한 계속해서 훈련

배치 크기
일반적으로 미니 배치의 배치 크기는 10에서 1000 사이
SGD의 경우 배치 크기는 1이다. 배치 크기의 상한은 컴퓨터의 메모리에 들어갈 수 있는 데이터 양에 의해 제한

배치 크기에 대한 하한은 데이터와 알고리즘에 따라 달라짐.
더 작은 배치 크기를 사용하면 epoch당 그라데이션 업데이트를 더 자주 할 수 있으며, 이는 epoch당 손실이 더 크게 감소할 수 있음.

작은 배치를 사용하여 훈련된 모델은 더 잘 일반화됨

층의 깊이와 폭
신경망에서 깊이는 층수를, 너비는 층당 뉴런 수를 가리킴.
문제의 복잡성이 증가함에 따라 깊이와 폭을 증가

깊이와 폭이 꼭 맞아야 할 필요는 없다는 것을 기억하라. 나중에 모델을 최적화할 때 값을 조정
```

```
하이퍼 파라미터에서 교육손실액 < 검증 손실액보다 크면 
교육 및 검증 세트가 동일한 통계 정보를 가지고 있는지 확인하거나 오버핏을 방지하려면 정규화를 사용하여 오버핏 방지를 해야함! 


```