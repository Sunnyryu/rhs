# 머신러닝

```
정확성이 좋은 모델을 만들어서 정확하게 분류를 했다고치자..
새로운 데이터(사례)가 들어오면서 모델이 이상해지고 안 좋아질 수 있음
(필요 이상의 모델을 만들 경우에도 과적합 발생 증가)
과적합 할 수 있음! (새로운 데이터 분류 적합x!)
지나치게 복잡하면 (과적합이 되면) 문제가 되옵니다.
(과적합은 모델이 새 데이터에 맞게 잘 일반화되지 않을 정도로 근접하게 학습 데이터를 적합하려고 시도하는 경우 발생)

숨겨진 프로세스 -> 실제데이터 -> 학습 모델 -> 예측 새 샘플 <- 숨겨진 프로세스(진실)

ex) 이메일 , 특정 그림(데이터 샘플!)

목표 : 숨겨진 실제 분포에서 추출된 새로운 데이터를 제대로 예측
문제 : 진실을 알 수 없음 ( 분포에서 추출된 샘플만 볼 수 있음!)
모델 h가 현재 샘플에 적합하면 다른 새로운 샘플도 잘 예측할 것이라고 신뢰할 수 있나?

일반화이론 (모델의 단순성/복잡성 측정 아이디어를 기반으로 함 )

데이터 분포에서 새로운 사례를 뽑아 모델을 시험 / 새로운 데이터 샘플을 얻음!(테스트 세트 방법!)
데이터 분포에서 하나의 데이터 사례를 추출하여 모델 학습(학습 세트!)

학습 세트 - 모델을 학습시키기 위한 하위 세트
테스트 세트 - 모델을 테스트하기 위한 하위 세트
테스트 세트가 충분히 크거나 반복적으로 사용하지 않은 경우 (새로운 데이터에서도 잘 작동할 것이라고 예측!)

분포에서 독립적이고 동일한 방식으로 임의로 예를 추룰 / 분포가 정상성을 보이며 시간이 지나도 변하지 않음, 학습 유효성 검사 및 테스트 세트를 항상 같은 분포에서 추출!

ML 모델이 덜 복잡할수록 샘플의 특성 때문이 아니어도 좋은 경험적 결과를 얻을 가능성이 높습니다.

머신러닝의 목표는 이전에 보지 못한 새 데이터를 잘 예측하는 것임.
```

```
학습 세트 - 모델을 학습시키기 위한 데이터 세트의 일부분
평가 세트 - 모델을 테스트하기 위한 데이터 세트의 일부분

데이터 세트 하나를 학습 세트와 평가 세트로 분할 
통계적으로 유의미한 결과를 도출할 만큼 커야 합니다.
데이터 세트를 전체적으로 나타내야 합니다. 즉, 평가 세트가 학습 세트와 같은 특징을 가지도록 선별해야 합니다

데이터에도 일반화될 수 있는 모델을 만드는 것이 목표
평가 세트는 새 데이터를 모의 실험하는 역할

테스트 데이터로 학습하지 마세요. 평가 측정항목에서 이상할 정도로 좋은 결과가 나온다면 실수로 평가 세트로 학습했다는 증거( 너무 높을 시 테스트 데이터가 학습 세트로 유출 가능성도 있음!)
```

```
예제 수행
학습률을 낮추면 (손실이 떨어짐-> 테스트 손실이 / 대부분의 실행에서는 배치 크기를 늘려도 학습 손실 또는 테스트 손실에 영향x, 소수는 영향 !)

학습/평가 데이터 비율을 50%에서 10%로 줄이면 학습 세트의 데이터 포인트 수가 급격히 감소 / 데이터가 적은데 배치 크기와 학습률이 높으면 학습 모델이 최저점을 넘나들며 불규칙적으로 크게 변화!
```

```
테스트 세트 및 학습 세트를 사용하여 모델 개발 반복 과정 진행 -> 반복 과정에서는 학습 데이터 학습  / 테스트 데이터로 평가, 테스트 데이터에 대한 평가 결과를 근거로 학습률, 특성 등의 다양한 모델 초매개 변수 선택 변화

=> 절차를 많이 반복하면 특정 테스트 세트의 특이성에 은연중에 적용할 수 있음
(자주 평가할 수록 해당 테스트 세트에 대한 암시적 과적합이 나타날 위험 증가!)
```

```
테스트 세트의 결과에 따라 모델 조정 -> 학습 세트로 모델을 학습 -> (학습률 등의 설정 약간 조정) -> 테스트 세트로 모델 평가 -> 테스트 세트의 결과에 따라 모델 조정(몇몇 변수 추가 / 빼는 작업 반복!) -> (테스트 세트에서 가장 우수한 결과를 보이는 모델 선택 )

'모델 조정'이란 학습률 변경, 특성 추가 또는 삭제, 완전히 새로운 모델 설계와 같이 모델에서 가능한 모든 요소를 조정함을 의미


테스트 데이터만의 특성에 과적합한 모델이 나올 수 있음! => 검증데이터라는 3번째 데이터 세트를 만듬! (모집단에서)

학습데이터로 학습시키고 데이터 평가에는 검증데이터만 사용하는 약간 개선된 반복방식

학습 세트로 모델을 학습 -> 검증세트로 모델을 평가 -> 검증세트의 결과에 따라 모델을 조정 (반복) -> 검증세트에서 가장 우수한 결과를 보이는 모델 선택 -> 테스트 세트의 결과확인 (테스트데이터 결과 = 검증데이터 결과 / 만약 일치하지 않으면 검증세트에 과작합한 모델일 가능성 증가!!)

테스트 세트와 검증세트는 반복 사용에 따라 마모! 
즉, 초매개변수 설정 또는 기타 모델 개선을 결정할 때 같은 데이터를 더 많이 사용할수록 이러한 결과가 새로운 미지의 데이터까지 일반화될 가능성은 낮아짐. 일반적으로 검증세트의 마모 속도는 테스트 세트보다 느립니다.

가능하면 데이터를 더 수집하여 테스트 세트와 검증세트를 '갱신'하는 것이 좋습니다. 새로 시작하는 것도 좋은 재설정하기!
```

```
데이터를 가져와서 특성 벡터를 만들어야함 (원시 데이터에서 특성을 추출하는 과정 -> 특성추출! ) / 상당한 시간소요 / 실수 벡터로 가중치 표현이 좋음!

방의 개수 같이 실제 값으로 표현할 수 있는 기록은 특성 벡터로 사용할 수 있음!
(실수값 피쳐!)

문자열의 경우(가능한 값의 어휘로 지칭할 특성 값에서 정수로의 매핑을 정의함으로써 가능)
 원-핫 인코딩을 사용해 특성 벡터로 바꿈! (모든 문자열마다 각각 고유한 개수를 가짐!) / 분산되어 있는 분류 데이터에 적합! (단일 값이 1일 때는 원-핫인코딩 , 여러값이 1일 때는 멀티 ㅡ 핫 인코딩이라고 함!)

좋은 특성의 조건 
좋은 특성 값은 데이터 세트에서 5회 이상 나타나야함!
(특성 값은 데이터 세트에서 너무 적지 않은 일정 횟수 이상 0이 아닌 값으로 나타나야함!) / 명확하고 알기 쉬운 의미를 가져야함! /특성은 특수 값을 표함 해선 안되여! / 시간이 지남에 따라 특성 값이 편해서도 안되여
/ 특성은 이상점 값을 가져서는 안되옵니다. / 특성을 제한하거나 이상점을 제거해야할 경우도 나오긴함!

좋은 부동 소수점 특성은 특이한 범위 외 불연속성 또는 '특수' 값을 포함
(특성 하나는 특수 값 없이 오로지 품질 등급만 갖음, 특성 하나는 quality_rating이 입력되었는지 여부를 나타내는 부울 값을 갖습니다. 이 부울 특성에 is_quality_rating_defined와 같은 이름을 지정합니다.)

조정이란 부동 소수점 특성 값을 100~900 등의 자연 범위에서 0~1 또는 -1~+1 등의 표준 범위로 변환하는 작업

특성세트가 여러 특성으로 구성되었다면,
경사하강법이 더 빠르게 수렴됩니다.
'NaN 트랩'이 방지됩니다. NaN 트랩이란 모델의 숫자 중 하나가 NaN(예: 학습 중에 값이 부동 소수점 정밀도 한도를 초과하는 경우)이 된 후 수학 연산 과정에서 모델의 다른 모든 숫자가 결국 NaN이 되는 상황입니다.
모델이 각 특성의 적절한 가중치를 익히는 데 도움이 됩니다. 특성 조정을 수행하지 않으면 모델에서 범위가 더 넓은 특성을 과도하게 중시합니다.


비닝기법! (각각 새로운 고유 특성에 매핑되는 몇개의 부울빈을 만듬 -> 모델에서 각 빈에 서로 다른 값을 적용!)

 실무에서는 다음과 같은 이유로 데이터 세트의 여러 예를 신뢰할 수 없습니다.

값 누락. 예를 들어 사용자가 주택의 연령을 실수로 입력하지 않았을 수 있습니다.
중복 예. 예를 들어 서버에서 같은 로그를 실수로 두 번 업로드했을 수 있습니다.
잘못된 라벨. 예를 들어 사용자가 참나무 사진에 실수로 단풍나무 라벨을 지정했을 수 있습니다.
잘못된 특성 값. 예를 들어 사용자가 숫자를 실수로 입력했거나 온도계를 햇빛에 두었을 수 있습니다.
(잘못된 예가 발견시 데이트 세트에서 삭제하여 해당 예를 수정!)

철저한 데이터 파악
시각화(히스트그램, 분산형 플롯등으로 시각화) / 디버그(중복된 예가 있는지, 누락된 값이 있는지, 이상점이 있는지, 데이터가 대시보드와 일치하나, 학습 데이터와 검증데이터가 서로비슷한지 ) / 모니터링(특성 분위 및 시간에 따른 예의 수)
모델에 포함된 특성이 적을수록 리소스 사용이 감소하며 유지보수도 쉬워짐

```