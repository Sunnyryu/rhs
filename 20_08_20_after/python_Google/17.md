# 머신러닝(클러스터링 3)

```
클러스터링 알고리즘 실행

머신러닝(machine Learning)에서는 때때로 수백만 개의 데이터셋을 가질 수 있음 
ML 알고리즘은 이러한 대규모 데이터셋에 맞춰 효율적으로 확장해야함  
클러스터링 알고리즘은 계산을 해야하기 때문에 확장되지 않음 
(모든 점 쌍 간의 유사성 이것은 그들의 런타임이 다음과 같이 증가한다는 것을 의미)

k-평균은 대략적인 원형 군집을 발견
개념적으로 이것은 k-평균은 데이터를 대략적인 원형으로 구성된 것으로 효과적으로 처리
분포 및 이러한 분포에 해당하는 클러스터를 찾으려고 함
데이터에는 특이치가 포함되어 있으므로 이러한 모형에 적합하지 않을 수 있음

k-평균을 실행하기 전에 클러스터 수인 \(k\)를 선택

k-평균 군집 알고리즘
데이터를 \(k\) 클러스터로 클러스터링하려면 다음 단계를 수행

알고리즘은 각 클러스터에 대해 임의로 중심을 선택 -> 알고리즘은 k 이니셜을 얻기 위해 각 점을 가장 가까운 중심에 할당 -> 모든 클러스터에 대해 알고리즘은 평균을 취하여 센터를 다시 계산 -> 군집의 모든 점에 대해 설명 (화살표. 중심점이 바뀌기 때문에 알고리즘이 점을 재할당) -> 알고리즘은 중심 계산과 포인트 할당을 반복 (군집 변경을 중지할 때까지, 데이터셋을 클러스터링할 때 중지 수렴에 도달하기 전에 다른 기준을 사용하여 선택! )

처음에는 중심 위치가 랜덤으로 선택되기 때문에 k-평균은 연속 주행에서 상당히 다른 결과를 반환 / 
를 해결하기 위해 문제, k-means를 여러 번 실행하고 최상의 품질로 결과를 선택
```

```
클러스터링은 관리되지 않으므로 확인할 수 있는 "진실"이 없음 / 진실의 부재는 질을 평가하는 것을 복잡하게 만듬 / 현실세계 데이터 집합은 일반적으로 다음과 같은 명백한 예제 클러스터에 속하지 않음

EX) 플로우차트는 고객님의 품질을 확인하는 방법을 요약한 것 /
클러스터링으로 인해 클러스터링 품질을 확인하는 것은 엄격한 프로세스가 아닙니다. 진실성이 결여되어 있다 다음은 환경 개선을 위해 반복적으로 적용할 수 있는 지침

클러스터가 예상대로 보이는지 육안 검사를 수행 / 아래의 3개의 매트릭이 사용되옴!
클러스터 카디널리티( 클러스터당 예제의 수)
군집 규모(모든 예에서 중심까지의 거리의 합이다. 
성단 카디널리티와 유사하게, 그 크기가 어떻게 변하는지 체크한다)
다운스트림 시스템의 성능

유사성 측정의 성과 (클러스터링 알고리즘은 유사성 측정에 불과)
(각 예제 쌍에 대한 유사성 측도를 계산)

최적의 클러스터 수
k-평균에서는 군집 개수를 결정해야함 / k의 최적값을 결정 / 알고리즘을 실행
세분화된 클러스터를 선호한 다음 더 높은 k를 선택할 수 있음
```

```
k-평균의 장점과 단점
k-means의 장점
비교적 간단하게 구현할 수 있습니다.
대규모 데이터 세트로 확장
수렴을 보장합니다.
센트로이드 위치를 예열할 수 있습니다.
새로운 예에 쉽게 적응합니다.
다양한 모양의 클러스터로 일반화합니다. 타원형 군집과 같은 크기

단점 
수동으로 k를 선택해야함 
초기값에 종속되어 있음
크기와 밀도가 다양하다보니 군집 데이터를 클러스터링하는 데 문제가 있음
클러스터링 특이치(센터를 끌거나 자체 클러스터를 가져올 수 있음 / 제거하거나 잘라내기전에 고려)
치수 개수로 스케일링함 (치수 수가 증가함에 따라 거리 기반 유사도 측정 주어진 예시 간에 일정한 값으로 수렴)

스펙트럼 클러스터링은 별도의 클러스터링 알고리즘이 아니라 프리-프로그래밍
```

```
k-평균 클러스터링 구현
전체 데이터 집합 대신 미니 배치를 사용하여 클러스터링합니다.
k-means++를 사용하여 보다 최적의 초기 클러스터를 선택하면 수렴 속도가 빨라집니다.



```