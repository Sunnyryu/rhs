# 머신러닝(테스팅 / 디버깅 2)

```
모델 메트릭을 사용하여 품질 평가

모델의 품질을 평가하기 위해 일반적으로 사용되는 메트릭은 
손실, 정확도, 정밀 & 재현, ROC 곡선(AUC) 아래의 영역

회귀분석: MSE(절대 평균 제곱 오차)를 줄이는 것 외에 레이블 값에 대비하여 MSE를 줄임

다중클래스 분류 : 소수의 클래스를 예측하는 경우 클래스별 메트릭을 개별적으로 살피고 여러 클래스에서 예측하는 경우 클래스별 메트릭을 평균하여 전체 분류 메트릭을 추적할 수 있음 / 필요에 따라 특정한 품질 목표를 우선순위로 정할 수 있음

중요한 데이터 조각에 대한 메트릭 확인

고품질 모형을 만든 후에도 모형이 데이터의 하위 집합에서 여전히 좋지 않은 성능을 발휘할 수 있음
부분집합과 같은 데이터의 하위집합은 데이터 조각이라고 불림 / 데이터 조각을 별도로 모니터링

관심 있는 데이터 조각을 식별하려면 데이터에 대한 이해도를 사용
음 데이터 조각의 모델 메트릭을 전체 데이터 세트의 메트릭과 비교
모형이 모든 데이터 슬라이스에서 수행되는지 확인하는 것은 치우침을 제거하는 데 도움이 됌..

실제 메트릭 사용

모델 메트릭스가 반드시 모델의 실제 영향을 측정하는 것은 아님.
하이퍼 파라미터를 변경하고 AUC를 증가시킬 수 있지만, 변경사항이 사용자 경험에 어떤 영향을 미쳤는가를 확인 

실제 영향을 측정하려면 별도의 측정 기준을 정의 

실제 영향 측정은 모델의 여러 반복 품질을 비교하는 데 도움이 됌
```

```
발현시기 에측 -> MSE 15 / 개선사항입니까? (25분)
예 (MSE 낮을 수록 품질이 우수함을 나타냄)

실제 메트릭이 모델 메트릭을 보완할 수 있나여?

사용자가 앱에서 예측을 확인한 후 해당 앱을 사용하는 경우(용자가 예측을 확인한 후 앱을 사용하는 경우 다시 한번 말하지만, 그 예측은 아마도 충분히 정확했을 것)

보고서가 온라인에 게시 (온라인 보고서를 사용하여 다음 중 어느 쪽인지 확인할 수 있음) / 당신의 예측치가 출현 예측 / 보고서에 게시

모델 최적화

모델이 작동하면 모델의 품질을 최적화할 수 있음.

유용한 기능 추가

정보를 인코딩하지 않는 기능을 추가하여 모델 성능을 향상시킬 수 있음 
기존 기능에 의해 인코딩
선형 상관 관계를 찾을 수 있음
상관 행렬을 사용하여 개별 피쳐와 레이블 사이에 있음
형상과 레이블 사이의 비선형 상관 관계를 탐지하려면 형상 또는 조합을 포함하거나 포함하지 않고 모델을 교육해야 함
기능 및 모델 품질의 증가를 확인 및 정당화해야함

하이퍼패러미터 튜닝

모형이 작동하도록 만드는 하이퍼 모수 값을 찾음 / 하이퍼 매개변수 값은 여전히 조정될 수 있음
수동으로도 조정가능 / 수동조정은 시간이 많이 걸림!

모형 깊이 및 폭 조정 

모형을 디버깅하는 동안 모형 깊이와 너비만 늘렸음 / 모형 최적화 중에 깊이를 늘리거나 줄임
목표에 따라 너비가 달라짐 / 모델 품질이 적절하면 깊이와 폭을 줄임으로써 오버핏과 트레이닝 시간을 줄여 보기!
연속적인 각 층에서 폭을 반으로 줄임 / 모델 품질도 감소하므로 품질의 균형 유지 / 과적응과 트레이닝 시간 필요 

더 높은 모델의 품질이 필요한 경우 , 깊이나 너비등을 높이구.. 실제적으로 제한적이라구 생각하자.

깊이와 너비가 하이퍼 매개변수이므로 하이퍼 매개변수를 사용할 수 있음!
```

```
ML 파이프라인 개요

ML 파이프라인은 다이어그램에서 알 수 있듯이 몇 가지 구성요소로 구성됩니다. 우리는 이 부품들은 나중에 친숙해진다. 일단 "모델"이 (블랙박스)는, 을 위해 필요한 파이프라인 인프라의 작은 부분

데이터 수집 / 데이터 검증 / 머신러닝 관리 / 서빙 인프라스트럭쳐/ 분석 도구 / 모델 / 피쳐 추출 / 프로세스 관리 도구 /  구성 / 모니터링 

ML 파이프라인에서의 테스트 역할

테스트 데이터, 모델 및 문제에 따라 달라짐

입력 데이터의 유효성을 확인하는 중
기능 엔지니어링을 확인하는 중
새 모델 버전의 품질 확인 중
서비스 인프라 검증
파이프라인 구성 요소 간의 통합 테스트
```

```
기계 학습 모델 배포 테스트

재현 가능한 훈련을 통한 테스트 모델 업데이트

무작위 숫자 생성기(RNG)를 결정적으로 시드

모델 구성 요소를 고정된 순서로 초기화하여 구성 요소가 다음을 얻을 수 있도록 함!(매번 실행될 때마다 RNG로부터 같은 난수. 일반적으로 ML 라이브러리 이 요구 사항을 자동으로 처리)

사양 및 API 호출에 대한 모델 업데이트 테스트

API 호출 테스트
단위 검정을 작성하여 랜덤 입력 데이터를 생성 

알고리즘 정확도 테스트
알고리즘상 모형이므로 예측해야함 (모형의 알고리즘 정확도를 확인해야함!)

모델을 몇 번 반복적으로 교육하고 손실이 감소하는지 확인
알고리즘을 정규화하지 않고 교육 / 특정 하위 컴퓨팅 테스트 알고리즘!

파이프라인 구성요소에 대한 쓰기 통합 테스트

구성 요소가 함께 작동하는지 확인 / 전체 파이프라인이 끝에서 끝까지 연결 (통합 테스트라고함)

통합 테스트를 연속적으로 실행하는 것 외에 통합 테스트를 실행
새 모델과 새 소프트웨어 버전을 푸시할 때. 느릿느릿 (전체 파이프라인은 연속 통합 테스트를 어렵게 만듬)

더 빨리 테스트하고 데이터의 부분 집합 또는 더 단순한 모델을 사용하여 훈련 / 세부사항 모델과 데이터에 의존, 지속적인 보장을 받기 위해..

모든 새로운 버전의 모델 또는 소프트웨어로 실행 가능 (느린 테스트는 백그라운드에서 계속 실행!)

서비스하기 전에 모델 품질 확인
갑작스러운 성능 저하: 새 버전의 버그는 심각한 문제를 일으킬 수 있음 / 
저속 성능 저하: 갑작스러운 저하에 대한 테스트가 느리게 감지되지 않을 수 있음

서비스하기 전에 모델-인프라 호환성 검증
모델이 서버보다 빠르게 업데이트되면 모델이 업데이트 / 서버와 다른 소프트웨어 종속성, 잠재적으로 유발 양립 불능 모델에서 사용하는 작업인지 확인 / 모델 스테이징으로 서버 존재 

```